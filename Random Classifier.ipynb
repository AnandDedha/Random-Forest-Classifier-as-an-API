{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Classification\n",
    "\n",
    "Classification: It is the method of identifying to which  set of categories a new observations belongs.It is a supervised learning model. For example Assigning an email into \"spam\" or \"Ham\" category.\n",
    "\n",
    "Image_01\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "It is a versatile algorithm capable of performing both\n",
    "\n",
    "1) Regression\n",
    "2) Classification\n",
    "\n",
    "In terms of classification, it is an ensemble classifier made using many decision tree models.\n",
    "Ensemble methods use multiple machine learning algorithim to obtain better predict model.\n",
    "\n",
    "Image_02\n",
    "\n",
    "\n",
    "## How Random forest Works\n",
    "\n",
    "1) Randomly select m feautures from T: where m < T\n",
    "        \n",
    "        T: Total number of features\n",
    "\n",
    "2) For node d, calculate the best split point among the m feature. \n",
    "\n",
    "    Best split is achieved when information gain is highest.\n",
    "    \n",
    "    Information gain: High entropy - low entropy\n",
    "    \n",
    "    Entropy: It is the measure of randomness or unpredictabilty in the dataset\n",
    "\n",
    "3) Split the node into further nodes using the best split\n",
    "\n",
    "4) Build the forest by repeating above steps D number of times\n",
    "\n",
    "        D: Numbers of trees to be constructed\n",
    "  \n",
    "\n",
    "## Why Random Forest ?\n",
    "\n",
    "1) No Overfitting\n",
    "  \n",
    "      a) Use of multiple trees reduce the risk of overfitting \n",
    "  \n",
    "      b) Traning time is less too\n",
    "  \n",
    "2) High accuracy\n",
    "  \n",
    "      a) Runs efficiently on large database\n",
    "  \n",
    "3) Maintain the accuracy even when a large portion of data is missing \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DSD-PC2\\Desktop\\Certifications\\Python\\Deploying Machine Learning Models Using Dockers\n",
      "0.973333333333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Project: Random Forest Classifier API\n",
    "Author: Anand Kumar \n",
    "Created: Saturday June 16, 2018\n",
    "Info: Building a random classifier API using flask library on Iris Dataset\n",
    "\"\"\"\n",
    "#Random Forest Classifier\n",
    "#Loading the Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "#Library to serialize and de-serialize the python object \n",
    "import pickle \n",
    "\n",
    "#Checking the current working directory\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "#Loading the dataset\n",
    "iris= load_iris()   #Creating an object called iris to store iris datasets\n",
    "\n",
    "# Exploring the data\n",
    "#print(iris)\n",
    "#df= pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "#print(df.head())\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "#Spilt the dataset into test and train models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size =0.5)\n",
    "\n",
    "#Build the model\n",
    "clf_model = RandomForestClassifier(n_estimators =10)\n",
    "\n",
    "#Train the clasifier\n",
    "clf_model.fit(X_train, y_train)\n",
    "\n",
    "#Predictions\n",
    "predicted =clf_model.predict(X_test)\n",
    "\n",
    "#check accuracy\n",
    "print(accuracy_score(predicted, y_test))\n",
    "\n",
    "#Pickling file with name rf.pkl is stored in current working directory\n",
    "with open('rf.pkl', 'wb') as model_pkl:\n",
    "          pickle.dump(clf_model, model_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [17/Jun/2018 20:59:43] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [17/Jun/2018 20:59:50] \"GET /predict?s_length=5.9&s_width=5.4&p_length=6.7&p_width=6.6 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#Loading the Libraries\n",
    "import pickle\n",
    "from flask import Flask, request\n",
    "import numpy as np\n",
    "\n",
    "with open('rf.pkl','rb') as model_file:\n",
    "     model = pickle.load(model_file)\n",
    "        \n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict')\n",
    "\n",
    "def predict_iris():\n",
    "    s_length = request.args.get(\"s_length\")\n",
    "    s_width = request.args.get(\"s_width\")\n",
    "    p_length = request.args.get(\"p_length\")\n",
    "    p_width = request.args.get(\"p_width\")\n",
    "    \n",
    "    prediction = model.predict(np.array([[s_length, s_width, p_length,p_width]]))\n",
    "    \n",
    "    return str(prediction)\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
