{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Classification\n",
    "\n",
    "Classification: It is the method of identifying to which  set of categories a new observations belongs.It is a supervised learning model. For example Assigning an email into \"spam\" or \"Ham\" category.\n",
    "\n",
    "Image_01\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "It is a versatile algorithm capable of performing both\n",
    "\n",
    "1) Regression\n",
    "2) Classification\n",
    "\n",
    "In terms of classification, it is an ensemble classifier made using many decision tree models.\n",
    "Ensemble methods use multiple machine learning algorithim to obtain better predict model.\n",
    "\n",
    "Image_02\n",
    "\n",
    "\n",
    "## How Random forest Works\n",
    "\n",
    "1) Randomly select m feautures from T: where m < T\n",
    "        \n",
    "        T: Total number of features\n",
    "\n",
    "2) For node d, calculate the best split point among the m feature. \n",
    "\n",
    "    Best split is achieved when information gain is highest.\n",
    "    \n",
    "    Information gain: High entropy - low entropy\n",
    "    \n",
    "    Entropy: It is the measure of randomness or unpredictabilty in the dataset\n",
    "\n",
    "3) Split the node into further nodes using the best split\n",
    "\n",
    "4) Build the forest by repeating above steps D number of times\n",
    "\n",
    "        D: Numbers of trees to be constructed\n",
    "  \n",
    "\n",
    "## Why Random Forest ?\n",
    "\n",
    "1) No Overfitting\n",
    "  \n",
    "      a) Use of multiple trees reduce the risk of overfitting \n",
    "  \n",
    "      b) Traning time is less too\n",
    "  \n",
    "2) High accuracy\n",
    "  \n",
    "      a) Runs efficiently on large database\n",
    "  \n",
    "3) Maintain the accuracy even when a large portion of data is missing \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DSD-PC2\\Desktop\\Certifications\\Python\\Deploying Machine Learning Models Using Dockers\n",
      "0.973333333333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Project: Random Forest Classifier API\n",
    "Author: Anand Kumar \n",
    "Created: Saturday June 16, 2018\n",
    "Info: Building a random classifier API using flask library on Iris Dataset\n",
    "\"\"\"\n",
    "#Random Forest Classifier\n",
    "#Loading the Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "#Library to serialize and de-serialize the python object \n",
    "import pickle \n",
    "\n",
    "#Checking the current working directory\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "#Loading the dataset\n",
    "iris= load_iris()   #Creating an object called iris to store iris datasets\n",
    "\n",
    "# Exploring the data\n",
    "#print(iris)\n",
    "#df= pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "#print(df.head())\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "#Spilt the dataset into test and train models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size =0.5)\n",
    "\n",
    "#Build the model\n",
    "clf_model = RandomForestClassifier(n_estimators =10)\n",
    "\n",
    "#Train the clasifier\n",
    "clf_model.fit(X_train, y_train)\n",
    "\n",
    "#Predictions\n",
    "predicted =clf_model.predict(X_test)\n",
    "\n",
    "#check accuracy\n",
    "print(accuracy_score(predicted, y_test))\n",
    "\n",
    "#Pickling file with name rf.pkl is stored in current working directory\n",
    "with open('rf.pkl', 'wb') as model_pkl:\n",
    "          pickle.dump(clf_model, model_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "[2018-07-02 17:36:58,305] ERROR in app: Exception on /predict_file [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-9-3fda9fbdcbfe>\", line 28, in predict_iris_csv\n",
      "    input_data = pd.read_csv(request.files.get(\"Input_file\"), header=None)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 655, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 392, in _read\n",
      "    filepath_or_buffer, encoding, compression)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 210, in get_filepath_or_buffer\n",
      "    raise ValueError(msg.format(_type=type(filepath_or_buffer)))\n",
      "ValueError: Invalid file path or buffer object type: <class 'NoneType'>\n",
      "127.0.0.1 - - [02/Jul/2018 17:36:58] \"POST /predict_file HTTP/1.1\" 500 -\n",
      "[2018-07-02 17:37:12,122] ERROR in app: Exception on /predict_file [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-9-3fda9fbdcbfe>\", line 28, in predict_iris_csv\n",
      "    input_data = pd.read_csv(request.files.get(\"Input_file\"), header=None)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 655, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 392, in _read\n",
      "    filepath_or_buffer, encoding, compression)\n",
      "  File \"C:\\Users\\DSD-PC2\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 210, in get_filepath_or_buffer\n",
      "    raise ValueError(msg.format(_type=type(filepath_or_buffer)))\n",
      "ValueError: Invalid file path or buffer object type: <class 'NoneType'>\n",
      "127.0.0.1 - - [02/Jul/2018 17:37:12] \"POST /predict_file HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "#Loading the Libraries\n",
    "import pickle\n",
    "from flask import Flask, request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "with open('rf.pkl','rb') as model_file:\n",
    "     model = pickle.load(model_file)\n",
    "        \n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict')\n",
    "\n",
    "# Reading input in URl by users\n",
    "def predict_iris():\n",
    "    s_length = request.args.get(\"s_length\")\n",
    "    s_width = request.args.get(\"s_width\")\n",
    "    p_length = request.args.get(\"p_length\")\n",
    "    p_width = request.args.get(\"p_width\")\n",
    "    \n",
    "    prediction = model.predict(np.array([[s_length, s_width, p_length,p_width]]))\n",
    "    \n",
    "    return str(prediction)\n",
    "\n",
    "# Reading the input via a CSV file by users\n",
    "@app.route('/predict_file', methods =[\"POST\"])\n",
    "def predict_iris_csv():\n",
    "    input_data = pd.read_csv(request.files.get(\"Input_file\"), header=None)    \n",
    "    prediction = model.predict(input_data)\n",
    "    return str(list(prediction))\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DSD-PC2\\Documents\\GitHub\\Random-Forest-Classifier-as-an-API\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
